# Gemini Agent Project Notes: SkyUp

This document provides context for the SkyUp project, a self-hosted application stack, for the Gemini agent.

## Project Overview

**Current Release:** v2.1 - Memory

SkyUp is a self-hosted application stack for running AI applications and workflow tools. It uses Podman and podman-compose for containerization. The stack is designed to be simple, accessible only from the host, and easily extendable for security hardening.

### Included Services

- **PostgreSQL (pgvector):** Vector-enabled database with four databases:
  - `postgres` (admin)
  - `n8n` (workflow metadata)
  - `open_webui` (user data with vector and uuid-ossp extensions)
  - `memory` (for n8n workflow chat memory and persistent data)
- **Ollama:** Local LLM service with Vulkan GPU acceleration
- **Open WebUI:** A user-friendly web interface for LLMs
- **n8n:** Workflow automation with basic auth protection
- **Nginx:** Reverse proxy with HTTPS support

## Repository Structure

The key files in this repository are:

- `podman-compose.yml`: Defines the services for the application stack.
- `.env`: Contains environment variables, including secrets and credentials (generated by `init-env.sh`).
- `init-env.sh`: A script to generate the initial environment variables and create required directories.
- `initdb/`: Contains PostgreSQL initialization scripts.
- `nginx.conf`: The configuration file for the Nginx reverse proxy.

## Special Requirements

### Data Persistence Pattern
- All service data follows this format: `.podman/[service-description]/`
  - `.podman/pgvector-varlibpostgresqldata/` - PostgreSQL data
  - `.podman/open-webui-appbackenddata/` - Open WebUI backend data
  - `.podman/n8n-homenode.n8n/` - n8n workflow data

### Configuration Management
- All passwords and secrets are stored in `.env` (generated by `init-env.sh`)
- Environment variables include:
  - POSTGRES_PASSWORD
  - N8N_DB_PASSWORD
  - OPEN_WEBUI_DB_PASSWORD
  - MEMORY_DB_PASSWORD
  - N8N_BASIC_USER / N8N_BASIC_PASSWORD

### Common Issues
- **n8n crash loop**: Due to file permission errors. The container runs as UID 1000. Fix: `sudo chown -R 1000:1000 .podman/n8n-homenode.n8n`
- **Container communication**: Use service names (e.g., `postgres`, `ollama`) not `localhost` or `127.0.0.1`
- **502 Bad Gateway from Nginx**: If you get a 502 error, restart Nginx to clear its DNS cache: `podman-compose restart nginx`
- **DB Connection Issues**: If you change `.env` passwords, update the DB users directly in `postgres` with `ALTER USER`.

## Setup and Operation

1. **Prerequisites:** Requires `podman`, `podman-compose`, `nginx`, and `certbot` (Fedora/RHEL/CentOS).

2. **Initialization:**
   - Run `chmod +x init-env.sh && ./init-env.sh` to generate the `.env` file with strong random passwords and create required data directories.
   - **WARNING**: Re-running init-env.sh will reset PostgreSQL and n8n data directories!

3. **Start Services:** Use `podman-compose up -d` to start the application stack.

4. **Database:**
   - PostgreSQL is accessible only from the host (`127.0.0.1:5432`)
   - Initialization scripts in `initdb/01-create-extra-dbs.sh` run on first startup
   - Creates 4 databases: postgres, n8n, open_webui, memory
   - pgvector extension enabled on open_webui database

5. **Admin Creation:** The first user to register in Open WebUI will become an admin.

6. **Accessing Services:**
   - Open WebUI: `http://127.0.0.1:8080` (first user becomes admin)
   - n8n: `http://127.0.0.1:5678` (Basic Auth - credentials in `.env`)
   - Ollama: `http://127.0.0.1:11434` (API only)

## Memory Database Usage

The `memory` database is specifically for n8n workflows to store:
- Chat conversation history
- Persistent workflow data
- Custom application data

**Connection from n8n workflows:**
- Host: `postgres` (service name)
- Port: `5432`
- Database: `memory`
- User: `memory_user`
- Password: From `MEMORY_DB_PASSWORD` in `.env`

## Ollama Model Management

```bash
# List models
podman exec -it ollama ollama list

# Pull a model
podman exec -it ollama ollama pull llama3.2

# Remove a model
podman exec -it ollama ollama rm model-name
```

Models are persisted in `/root/.ollama` on the host.

This information should provide the Gemini agent with a comprehensive understanding of the SkyUp project, its components, and how to interact with it.
